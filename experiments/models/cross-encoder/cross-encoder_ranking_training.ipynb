{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cross-Encoder ranking model",
   "id": "9bc0d925463af42e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data loading",
   "id": "f83bc7af753be01f"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-17T20:03:51.174922Z",
     "start_time": "2025-05-17T20:03:50.614811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_from_disk\n",
    "from src.utils.config_management import CONFIG"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:03:51.338059Z",
     "start_time": "2025-05-17T20:03:51.318625Z"
    }
   },
   "cell_type": "code",
   "source": "hf_dataset = load_from_disk(CONFIG['paths']['data']['dalip_hf_dataset'])",
   "id": "8b860895efd9c9e6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:03:51.361567Z",
     "start_time": "2025-05-17T20:03:51.354905Z"
    }
   },
   "cell_type": "code",
   "source": "hf_dataset",
   "id": "1d2094a8ab250814",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer_id', 'question_id', 'answer_creation_date', 'answer_score', 'answer_normalized_score', 'answer_log_normalized_score', 'answer_body', 'answer_last_edit_date', 'answer_last_activity_date', 'answer_comment_count', 'answer_community_owned_date', 'question_creation_date', 'question_score', 'question_view_count', 'question_body', 'question_last_edit_date', 'question_last_activity_date', 'question_title', 'question_tags', 'question_answer_count', 'question_comment_count', 'question_favorite_count', 'question_closed_date', 'question_community_owned_date', 'answer_accepted'],\n",
       "        num_rows: 42700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer_id', 'question_id', 'answer_creation_date', 'answer_score', 'answer_normalized_score', 'answer_log_normalized_score', 'answer_body', 'answer_last_edit_date', 'answer_last_activity_date', 'answer_comment_count', 'answer_community_owned_date', 'question_creation_date', 'question_score', 'question_view_count', 'question_body', 'question_last_edit_date', 'question_last_activity_date', 'question_title', 'question_tags', 'question_answer_count', 'question_comment_count', 'question_favorite_count', 'question_closed_date', 'question_community_owned_date', 'answer_accepted'],\n",
       "        num_rows: 10563\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data preprocessing",
   "id": "d8d1b6fc0ab91a4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:03:51.474795Z",
     "start_time": "2025-05-17T20:03:51.383205Z"
    }
   },
   "cell_type": "code",
   "source": "from src.utils.text_preprocessing import Preprocessor",
   "id": "bde6798d564e3ca4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:03:51.578031Z",
     "start_time": "2025-05-17T20:03:51.574116Z"
    }
   },
   "cell_type": "code",
   "source": "preprocessor = Preprocessor(preserve_html_tags=['code'])",
   "id": "19aa545a200e9da4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:03:51.613137Z",
     "start_time": "2025-05-17T20:03:51.598988Z"
    }
   },
   "cell_type": "code",
   "source": "hf_dataset = hf_dataset.map(preprocessor, batched=True)",
   "id": "c31946c038001583",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:03:51.691457Z",
     "start_time": "2025-05-17T20:03:51.686975Z"
    }
   },
   "cell_type": "code",
   "source": "hf_dataset",
   "id": "bb45c826ddfb2120",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer_id', 'question_id', 'answer_creation_date', 'answer_score', 'answer_normalized_score', 'answer_log_normalized_score', 'answer_body', 'answer_last_edit_date', 'answer_last_activity_date', 'answer_comment_count', 'answer_community_owned_date', 'question_creation_date', 'question_score', 'question_view_count', 'question_body', 'question_last_edit_date', 'question_last_activity_date', 'question_title', 'question_tags', 'question_answer_count', 'question_comment_count', 'question_favorite_count', 'question_closed_date', 'question_community_owned_date', 'answer_accepted', 'question_text', 'answer_text'],\n",
       "        num_rows: 42700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer_id', 'question_id', 'answer_creation_date', 'answer_score', 'answer_normalized_score', 'answer_log_normalized_score', 'answer_body', 'answer_last_edit_date', 'answer_last_activity_date', 'answer_comment_count', 'answer_community_owned_date', 'question_creation_date', 'question_score', 'question_view_count', 'question_body', 'question_last_edit_date', 'question_last_activity_date', 'question_title', 'question_tags', 'question_answer_count', 'question_comment_count', 'question_favorite_count', 'question_closed_date', 'question_community_owned_date', 'answer_accepted', 'question_text', 'answer_text'],\n",
       "        num_rows: 10563\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine-tuning",
   "id": "88b83882127e4b27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create pairs dataset",
   "id": "df1067c25e68474"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:03:53.662013Z",
     "start_time": "2025-05-17T20:03:51.711627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "from src.data_management import create_pairs_dataset_df\n",
    "from datasets import Dataset"
   ],
   "id": "62a440ec4d3488ae",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:03:53.840546Z",
     "start_time": "2025-05-17T20:03:53.689175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "TARGET_COL = 'answer_normalized_score'\n",
    "PAIRS_SAMPLING_STRATEGY = 'mean'\n",
    "N_SAMPLES = 'all'\n",
    "MODEL_PATH = 'mmukh/SOBertLarge'\n",
    "MODEL_NAME = MODEL_PATH.split('/')[-1]\n",
    "MAX_LENGTH = 1024\n",
    "BATCH_SIZE = 1\n",
    "GRADIENT_ACCUMULATION_STEPS = math.ceil(4 / BATCH_SIZE)\n",
    "LOSS = 'margin_ranking_loss'\n",
    "MODEL_OUTPUT_PATH = os.path.join(CONFIG['paths']['models']['dalip_cross-encoder_ranking'],\n",
    "                                 f'cross-encoder_ranking_{MODEL_NAME}')"
   ],
   "id": "57ff34458f741481",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:04:10.110848Z",
     "start_time": "2025-05-17T20:03:53.867720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset_df = pd.DataFrame(hf_dataset['train'])\n",
    "test_dataset_df = pd.DataFrame(hf_dataset['test'])"
   ],
   "id": "daf000b9980ab175",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:04.079485Z",
     "start_time": "2025-05-17T20:04:10.147970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_pairs_dataset_df = create_pairs_dataset_df(train_dataset_df, pairs_sampling_strategy=PAIRS_SAMPLING_STRATEGY, n=N_SAMPLES,\n",
    "                                                 TARGET_COL=TARGET_COL)\n",
    "test_pairs_dataset_df = create_pairs_dataset_df(test_dataset_df, pairs_sampling_strategy='mean', n='all',\n",
    "                                                TARGET_COL=TARGET_COL)\n",
    "\n",
    "hf_dataset['test'] = hf_dataset['test'].rename_column('answer_text', 'answer_1_text')"
   ],
   "id": "28478b39ec1d7de9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7776/7776 [01:29<00:00, 86.89it/s] \n",
      "100%|██████████| 1945/1945 [00:22<00:00, 85.33it/s] \n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:05.758114Z",
     "start_time": "2025-05-17T20:06:04.132297Z"
    }
   },
   "cell_type": "code",
   "source": "train_pairs_dataset = Dataset.from_pandas(train_pairs_dataset_df)",
   "id": "7307f3e2617e12b8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define model and data collator",
   "id": "9821be29bb5c083a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:10.135228Z",
     "start_time": "2025-05-17T20:06:05.799468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from dataclasses import dataclass\n",
    "from transformers import PreTrainedTokenizerBase, MegatronBertForSequenceClassification, PreTrainedTokenizerFast"
   ],
   "id": "efcec28b9176977a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-17 20:06:08.356080: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-17 20:06:08.425033: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-17 20:06:08.425070: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-17 20:06:08.427867: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-17 20:06:08.440430: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-17 20:06:09.546936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:13.145168Z",
     "start_time": "2025-05-17T20:06:10.441710Z"
    }
   },
   "cell_type": "code",
   "source": "scorer_model = MegatronBertForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=1)",
   "id": "b21b0cc65abe79b8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MegatronBertForSequenceClassification were not initialized from the model checkpoint at mmukh/SOBertLarge and are newly initialized: ['bert.embeddings.token_type_embeddings.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:13.748918Z",
     "start_time": "2025-05-17T20:06:13.232812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "if not tokenizer.pad_token:\n",
    "    pad_token_id = scorer_model.bert.embeddings.word_embeddings.padding_idx\n",
    "    print(f'Setting pad token id to {pad_token_id}...')\n",
    "    tokenizer.pad_token_id = pad_token_id\n",
    "    print(f'Pad token set to {tokenizer.pad_token}')"
   ],
   "id": "ff64a7acfaa4b9e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pad token id to 0...\n",
      "Pad token set to <unk>\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:13.852955Z",
     "start_time": "2025-05-17T20:06:13.847001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CrossEncoderRanker(nn.Module):\n",
    "    def __init__(self, scorer_model):\n",
    "        super().__init__()\n",
    "        self.scorer = scorer_model\n",
    "\n",
    "    def gradient_checkpointing_enable(self, **gradient_checkpointing_kwargs):\n",
    "        if hasattr(self.scorer, 'gradient_checkpointing_enable'):\n",
    "            self.scorer.gradient_checkpointing_enable()\n",
    "        else:\n",
    "            raise NotImplementedError('Scorer model does not support gradient checkpointing.')\n",
    "\n",
    "    def gradient_checkpointing_disable(self, **gradient_checkpointing_kwargs):\n",
    "        if hasattr(self.scorer, 'gradient_checkpointing_disable'):\n",
    "            self.scorer.gradient_checkpointing_disable()\n",
    "        else:\n",
    "            raise NotImplementedError('Scorer model does not support gradient checkpointing.')\n",
    "\n",
    "    def forward(self, pairs_1_tokenized, pairs_2_tokenized=None, labels=None):\n",
    "        pair_1_scores = self.scorer(**pairs_1_tokenized).logits.squeeze(-1)\n",
    "\n",
    "        outputs = {'pair_1_scores': pair_1_scores}\n",
    "\n",
    "        if pairs_2_tokenized is not None:\n",
    "            pair_2_scores = self.scorer(**pairs_2_tokenized).logits.squeeze(-1)\n",
    "\n",
    "            outputs['pair_2_scores'] = pair_2_scores\n",
    "\n",
    "        return outputs"
   ],
   "id": "fc0854ef06f06a02",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:15.063745Z",
     "start_time": "2025-05-17T20:06:13.897445Z"
    }
   },
   "cell_type": "code",
   "source": "model = CrossEncoderRanker(scorer_model).to(device)",
   "id": "6d4c6b01fd770f85",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:15.182480Z",
     "start_time": "2025-05-17T20:06:15.175479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class CrossEncoderPairwiseDataCollator:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: bool = True\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        question_texts = []\n",
    "        answer_1_texts = []\n",
    "        answer_2_texts = []\n",
    "        labels = []\n",
    "\n",
    "        for sample in batch:\n",
    "            question_texts.append(sample['question_text'])\n",
    "            answer_1_texts.append(sample['answer_1_text'])\n",
    "            if 'answer_2_text' in sample:\n",
    "                answer_2_texts.append(sample['answer_2_text'])\n",
    "            if 'label' in sample:  # if training\n",
    "                labels.append(sample['label'])\n",
    "            else:  # if evaluation\n",
    "                labels.append(sample[TARGET_COL])\n",
    "\n",
    "        pairs_1_tokenized = self.tokenizer(question_texts, answer_1_texts, padding=self.padding, truncation='longest_first',\n",
    "                                           return_tensors='pt')\n",
    "\n",
    "        labels = torch.tensor(labels).float()\n",
    "\n",
    "        collated_batch = {\n",
    "            'pairs_1_tokenized': pairs_1_tokenized,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "        if answer_2_texts:\n",
    "            pairs_2_tokenized = self.tokenizer(question_texts, answer_2_texts, padding=self.padding, truncation='longest_first',\n",
    "                                           return_tensors='pt')\n",
    "\n",
    "            collated_batch['pairs_2_tokenized'] = pairs_2_tokenized\n",
    "\n",
    "        return collated_batch"
   ],
   "id": "da1ed78327d20c9b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:15.237912Z",
     "start_time": "2025-05-17T20:06:15.235062Z"
    }
   },
   "cell_type": "code",
   "source": "data_collator = CrossEncoderPairwiseDataCollator(tokenizer=tokenizer)",
   "id": "6b13cd8e8ab13930",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train model",
   "id": "4caf2725e7e0e2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:16.197810Z",
     "start_time": "2025-05-17T20:06:15.283581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from src.evaluation import RankingEvaluator\n",
    "import wandb\n",
    "import pandas as pd"
   ],
   "id": "3566b32abb0d4ea1",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:16.253287Z",
     "start_time": "2025-05-17T20:06:16.248435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if LOSS == 'margin_ranking_loss':\n",
    "    loss_fn = nn.MarginRankingLoss(margin=1.0)\n",
    "\n",
    "def trainer_loss_fn(outputs, labels, num_items_in_batch=None):\n",
    "    pair_1_scores = outputs['pair_1_scores']\n",
    "\n",
    "    if 'pair_2_scores' in outputs: # if training\n",
    "        pair_2_scores = outputs['pair_2_scores']\n",
    "        loss = loss_fn(pair_1_scores, pair_2_scores, labels)\n",
    "\n",
    "    else: # if evaluation\n",
    "        loss = torch.tensor(0.0)\n",
    "\n",
    "    return loss"
   ],
   "id": "114ac89ab3b0dc94",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:16.313659Z",
     "start_time": "2025-05-17T20:06:16.300737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_question_ids = hf_dataset['test']['question_id']\n",
    "\n",
    "evaluator = RankingEvaluator(ndcg_k=list(range(1, 11)),\n",
    "                             ndcg_gain_func='exponential', ndcg_discount_func='logarithmic')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    predictions_df = pd.DataFrame()\n",
    "    predictions_df['answer_id'] = hf_dataset['test']['answer_id']\n",
    "    predictions_df[TARGET_COL] = hf_dataset['test'][TARGET_COL]\n",
    "    predictions_df = predictions_df[:len(predictions)]\n",
    "    predictions_df['predicted_score'] = predictions\n",
    "\n",
    "    pairs_predictions_df = test_pairs_dataset_df.merge(predictions_df, left_on='answer_1_id', right_on='answer_id')\n",
    "    pairs_predictions_df = pairs_predictions_df.rename(columns={'predicted_score': 'answer_1_predicted_score'})\n",
    "    pairs_predictions_df = pairs_predictions_df.merge(predictions_df, left_on='answer_2_id', right_on='answer_id')\n",
    "    pairs_predictions_df = pairs_predictions_df.rename(columns={'predicted_score': 'answer_2_predicted_score'})\n",
    "\n",
    "    loss = loss_fn(torch.tensor(pairs_predictions_df['answer_1_predicted_score']),\n",
    "                   torch.tensor(pairs_predictions_df['answer_2_predicted_score']),\n",
    "                   torch.tensor(pairs_predictions_df['label']))\n",
    "\n",
    "    metrics = {LOSS: loss}\n",
    "    metrics.update(evaluator(labels, predictions, test_question_ids))\n",
    "    metrics.pop('mae')\n",
    "\n",
    "    wandb.log({'predictions_table': wandb.Table(dataframe=predictions_df)})\n",
    "\n",
    "    return metrics"
   ],
   "id": "dd7c4401d56759b1",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:16.436778Z",
     "start_time": "2025-05-17T20:06:16.407331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_OUTPUT_PATH,\n",
    "    logging_steps=1,\n",
    "    eval_steps=int(len(train_pairs_dataset_df) / BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS / 10),\n",
    "    eval_strategy = \"steps\",\n",
    "    save_strategy = \"epoch\",\n",
    "    save_total_limit=1,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    report_to='wandb',\n",
    "    remove_unused_columns=False,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adamw_8bit\"\n",
    ")"
   ],
   "id": "a15993a3fda30eb3",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T20:06:18.028953Z",
     "start_time": "2025-05-17T20:06:16.489410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run = wandb.init(\n",
    "    project='dalip-stackoverflow-answer-ranking',\n",
    "    tags=['cross-encoder', 'ranking']\n",
    ")\n",
    "\n",
    "wandb.config.update({\n",
    "    'preprocessing': preprocessor.__dict__,\n",
    "    'dataset': {\n",
    "        'pairs_sampling_strategy': PAIRS_SAMPLING_STRATEGY,\n",
    "        'n': N_SAMPLES\n",
    "    },\n",
    "    'model_name': MODEL_NAME,\n",
    "    'vectorizer': {\n",
    "        'vectorization_type': 'embeddings',\n",
    "        'max_length': MAX_LENGTH\n",
    "    },\n",
    "    'loss_fn': LOSS\n",
    "})\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_pairs_dataset,\n",
    "    eval_dataset=hf_dataset['test'],\n",
    "    compute_loss_func=trainer_loss_fn,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "2809710310e5673f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[32m\u001B[41mERROR\u001B[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mbunnynobugs\u001B[0m to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/stackoverflow-answer-assessment/wandb/run-20250517_200617-pe1glus9</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bunnynobugs/dalip-stackoverflow-answer-ranking/runs/pe1glus9' target=\"_blank\">daily-bush-139</a></strong> to <a href='https://wandb.ai/bunnynobugs/dalip-stackoverflow-answer-ranking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/bunnynobugs/dalip-stackoverflow-answer-ranking' target=\"_blank\">https://wandb.ai/bunnynobugs/dalip-stackoverflow-answer-ranking</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/bunnynobugs/dalip-stackoverflow-answer-ranking/runs/pe1glus9' target=\"_blank\">https://wandb.ai/bunnynobugs/dalip-stackoverflow-answer-ranking/runs/pe1glus9</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-17T20:06:18.079308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.train()\n",
    "run.finish()"
   ],
   "id": "52189f515767bc0b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='129040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    20/129040 01:44 < 208:37:19, 0.17 it/s, Epoch 0.00/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7877d12ebb7b566e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
