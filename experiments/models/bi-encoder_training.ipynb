{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bi-Encoder model",
   "id": "9bc0d925463af42e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data loading",
   "id": "f83bc7af753be01f"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-29T16:07:45.552288Z",
     "start_time": "2025-04-29T16:07:44.797777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_from_disk\n",
    "from src.utils.config_management import CONFIG"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:07:45.894531Z",
     "start_time": "2025-04-29T16:07:45.678978Z"
    }
   },
   "cell_type": "code",
   "source": "hf_dataset = load_from_disk(CONFIG['paths']['data']['dalip_hf_dataset'])",
   "id": "8b860895efd9c9e6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:07:45.919949Z",
     "start_time": "2025-04-29T16:07:45.913836Z"
    }
   },
   "cell_type": "code",
   "source": "hf_dataset",
   "id": "1d2094a8ab250814",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer_id', 'question_id', 'answer_creation_date', 'answer_score', 'answer_normalized_score', 'answer_log_normalized_score', 'answer_body', 'answer_last_edit_date', 'answer_last_activity_date', 'answer_comment_count', 'answer_community_owned_date', 'question_creation_date', 'question_score', 'question_view_count', 'question_body', 'question_last_edit_date', 'question_last_activity_date', 'question_title', 'question_tags', 'question_answer_count', 'question_comment_count', 'question_favorite_count', 'question_closed_date', 'question_community_owned_date', 'answer_accepted'],\n",
       "        num_rows: 42700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer_id', 'question_id', 'answer_creation_date', 'answer_score', 'answer_normalized_score', 'answer_log_normalized_score', 'answer_body', 'answer_last_edit_date', 'answer_last_activity_date', 'answer_comment_count', 'answer_community_owned_date', 'question_creation_date', 'question_score', 'question_view_count', 'question_body', 'question_last_edit_date', 'question_last_activity_date', 'question_title', 'question_tags', 'question_answer_count', 'question_comment_count', 'question_favorite_count', 'question_closed_date', 'question_community_owned_date', 'answer_accepted'],\n",
       "        num_rows: 10563\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data preprocessing",
   "id": "d8d1b6fc0ab91a4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:07:46.042820Z",
     "start_time": "2025-04-29T16:07:45.953898Z"
    }
   },
   "cell_type": "code",
   "source": "from src.utils.text_preprocessing import Preprocessor",
   "id": "bde6798d564e3ca4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:07:46.064764Z",
     "start_time": "2025-04-29T16:07:46.062323Z"
    }
   },
   "cell_type": "code",
   "source": "TARGET_COL = 'answer_normalized_score'",
   "id": "74325b357bf0412f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:07:46.091513Z",
     "start_time": "2025-04-29T16:07:46.088770Z"
    }
   },
   "cell_type": "code",
   "source": "preprocessor = Preprocessor(preserve_html_tags=['code'])",
   "id": "19aa545a200e9da4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:07:46.455460Z",
     "start_time": "2025-04-29T16:07:46.160528Z"
    }
   },
   "cell_type": "code",
   "source": "hf_dataset = hf_dataset.map(preprocessor, batched=True)",
   "id": "c31946c038001583",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:07:46.475482Z",
     "start_time": "2025-04-29T16:07:46.470505Z"
    }
   },
   "cell_type": "code",
   "source": "hf_dataset",
   "id": "bb45c826ddfb2120",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer_id', 'question_id', 'answer_creation_date', 'answer_score', 'answer_normalized_score', 'answer_log_normalized_score', 'answer_body', 'answer_last_edit_date', 'answer_last_activity_date', 'answer_comment_count', 'answer_community_owned_date', 'question_creation_date', 'question_score', 'question_view_count', 'question_body', 'question_last_edit_date', 'question_last_activity_date', 'question_title', 'question_tags', 'question_answer_count', 'question_comment_count', 'question_favorite_count', 'question_closed_date', 'question_community_owned_date', 'answer_accepted', 'question_text', 'answer_text'],\n",
       "        num_rows: 42700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer_id', 'question_id', 'answer_creation_date', 'answer_score', 'answer_normalized_score', 'answer_log_normalized_score', 'answer_body', 'answer_last_edit_date', 'answer_last_activity_date', 'answer_comment_count', 'answer_community_owned_date', 'question_creation_date', 'question_score', 'question_view_count', 'question_body', 'question_last_edit_date', 'question_last_activity_date', 'question_title', 'question_tags', 'question_answer_count', 'question_comment_count', 'question_favorite_count', 'question_closed_date', 'question_community_owned_date', 'answer_accepted', 'question_text', 'answer_text'],\n",
       "        num_rows: 10563\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine-tuning",
   "id": "88b83882127e4b27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:07:49.295253Z",
     "start_time": "2025-04-29T16:07:46.495699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import os"
   ],
   "id": "62a440ec4d3488ae",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:07:49.508Z",
     "start_time": "2025-04-29T16:07:49.313476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "MODEL_PATH = 'mmukh/SOBertLarge'\n",
    "MODEL_NAME = MODEL_PATH.split('/')[-1]\n",
    "MAX_LENGTH = 1024\n",
    "BATCH_SIZE = 2\n",
    "EMBEDDINGS_POOLING = 'mean'\n",
    "LOSS = 'MSE'\n",
    "MODEL_OUTPUT_PATH = os.path.join(CONFIG['paths']['models']['dalip_bi-encoder'],\n",
    "                                 f'bi-encoder_{MODEL_NAME}_{EMBEDDINGS_POOLING}')"
   ],
   "id": "57ff34458f741481",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1c6fda7d0d268256"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define model",
   "id": "9821be29bb5c083a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:07:58.908170Z",
     "start_time": "2025-04-29T16:07:49.531385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "import torch.nn as nn\n",
    "from transformers import PreTrainedTokenizerBase, MegatronBertModel, PreTrainedTokenizerFast"
   ],
   "id": "efcec28b9176977a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 16:07:54.452718: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-29 16:07:55.140921: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-29 16:07:55.140992: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-29 16:07:55.258949: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-29 16:07:55.505884: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-29 16:07:57.459422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:08:05.921201Z",
     "start_time": "2025-04-29T16:07:58.940289Z"
    }
   },
   "cell_type": "code",
   "source": "encoder_model = MegatronBertModel.from_pretrained(MODEL_PATH)",
   "id": "b21b0cc65abe79b8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MegatronBertModel were not initialized from the model checkpoint at mmukh/SOBertLarge and are newly initialized: ['embeddings.token_type_embeddings.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:08:06.384695Z",
     "start_time": "2025-04-29T16:08:05.997711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "if not tokenizer.pad_token:\n",
    "    pad_token_id = encoder_model.embeddings.word_embeddings.padding_idx\n",
    "    print(f'Setting pad token id to {pad_token_id}...')\n",
    "    tokenizer.pad_token_id = pad_token_id\n",
    "    print(f'Pad token set to {tokenizer.pad_token}')"
   ],
   "id": "ff64a7acfaa4b9e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pad token id to 0...\n",
      "Pad token set to <unk>\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:08:06.473300Z",
     "start_time": "2025-04-29T16:08:06.465391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BiEncoderRegressor(nn.Module):\n",
    "    def __init__(self, encoder_model, embeddings_pooling):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder_model\n",
    "        self.embeddings_pooling = embeddings_pooling\n",
    "        self.hidden_size = self.encoder.embeddings.word_embeddings.embedding_dim\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(2 * self.hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def get_sentence_embeddings(self, tokenized_inputs):\n",
    "        outputs = self.encoder(**tokenized_inputs)\n",
    "\n",
    "        attention_mask = tokenized_inputs['attention_mask']\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "        if self.embeddings_pooling == 'mean':\n",
    "            attention_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size())\n",
    "            sum_embeddings = (last_hidden_state * attention_mask_expanded).sum(dim=1)\n",
    "            sum_mask = attention_mask_expanded.sum(dim=1)\n",
    "            pooled = sum_embeddings / sum_mask\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def gradient_checkpointing_enable(self, **gradient_checkpointing_kwargs):\n",
    "        if hasattr(self.encoder, 'gradient_checkpointing_enable'):\n",
    "            self.encoder.gradient_checkpointing_enable()\n",
    "        else:\n",
    "            raise NotImplementedError('Encoder model does not support gradient checkpointing.')\n",
    "\n",
    "    def gradient_checkpointing_disable(self, **gradient_checkpointing_kwargs):\n",
    "        if hasattr(self.encoder, 'gradient_checkpointing_disable'):\n",
    "            self.encoder.gradient_checkpointing_disable()\n",
    "        else:\n",
    "            raise NotImplementedError('Encoder model does not support gradient checkpointing.')\n",
    "\n",
    "    def forward(self, questions_tokenized, answers_tokenized, labels=None):\n",
    "        question_embeddings = self.get_sentence_embeddings(questions_tokenized)\n",
    "        answer_embeddings = self.get_sentence_embeddings(answers_tokenized)\n",
    "\n",
    "        combined = torch.cat([question_embeddings, answer_embeddings], dim=1)\n",
    "\n",
    "        logits = self.regressor(combined).squeeze(-1)\n",
    "\n",
    "        return {'logits': logits}"
   ],
   "id": "c9aa43cf5bbf29c0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:08:07.504581Z",
     "start_time": "2025-04-29T16:08:06.501727Z"
    }
   },
   "cell_type": "code",
   "source": "model = BiEncoderRegressor(encoder_model, embeddings_pooling=EMBEDDINGS_POOLING).to(device)",
   "id": "d7f079ef6bccaa06",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train model",
   "id": "4caf2725e7e0e2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:08:08.882055Z",
     "start_time": "2025-04-29T16:08:07.536200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from src.evaluation import RankingEvaluator\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import math"
   ],
   "id": "3566b32abb0d4ea1",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:08:08.915841Z",
     "start_time": "2025-04-29T16:08:08.910671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class BiEncoderDataCollator:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: bool = True\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        question_texts = []\n",
    "        answer_texts = []\n",
    "        labels = []\n",
    "\n",
    "        for sample in batch:\n",
    "            question_texts.append(sample['question_text'])\n",
    "            answer_texts.append(sample['answer_text'])\n",
    "            labels.append(sample[TARGET_COL])\n",
    "\n",
    "        questions_tokenized = self.tokenizer(question_texts, padding=self.padding, truncation=True, max_length=MAX_LENGTH,\n",
    "                                             return_tensors='pt')\n",
    "        answers_tokenized = self.tokenizer(answer_texts, padding=self.padding, truncation=True, max_length=MAX_LENGTH,\n",
    "                                           return_tensors='pt')\n",
    "\n",
    "        labels = torch.tensor(labels).float()\n",
    "\n",
    "        collated_batch = {\n",
    "            'questions_tokenized': questions_tokenized,\n",
    "            'answers_tokenized': answers_tokenized,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "        return collated_batch"
   ],
   "id": "52e7f96bec647b9a",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:08:08.939958Z",
     "start_time": "2025-04-29T16:08:08.937573Z"
    }
   },
   "cell_type": "code",
   "source": "data_collator = BiEncoderDataCollator(tokenizer=tokenizer)",
   "id": "9730574ce560bb05",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:08:08.971545Z",
     "start_time": "2025-04-29T16:08:08.968565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def trainer_loss_fn(outputs, labels, num_items_in_batch=None):\n",
    "    logits = outputs['logits']\n",
    "\n",
    "    if LOSS == 'MSE':\n",
    "        loss_fn = nn.MSELoss()\n",
    "\n",
    "    loss = loss_fn(logits, labels)\n",
    "\n",
    "    return loss"
   ],
   "id": "114ac89ab3b0dc94",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:08:09.003461Z",
     "start_time": "2025-04-29T16:08:08.993826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_question_ids = hf_dataset['test']['question_id']\n",
    "\n",
    "evaluator = RankingEvaluator(ndcg_k=list(range(1, 11)),\n",
    "                             ndcg_gain_func='exponential', ndcg_discount_func='logarithmic')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    metrics = evaluator(labels, predictions, test_question_ids)\n",
    "    if TARGET_COL == 'answer_log_normalized_score':\n",
    "        metrics.pop('mae')\n",
    "\n",
    "    predictions_df = pd.DataFrame()\n",
    "    predictions_df['answer_id'] = hf_dataset['test']['answer_id']\n",
    "    predictions_df[TARGET_COL] = hf_dataset['test'][TARGET_COL]\n",
    "    predictions_df['predicted_score'] = predictions\n",
    "\n",
    "    wandb.log({'predictions_table': wandb.Table(dataframe=predictions_df)})\n",
    "\n",
    "    return metrics"
   ],
   "id": "dd7c4401d56759b1",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:08:09.101903Z",
     "start_time": "2025-04-29T16:08:09.072797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_OUTPUT_PATH,\n",
    "    logging_steps=1,\n",
    "    eval_steps=int(len(hf_dataset['train']) / BATCH_SIZE / 2),\n",
    "    eval_strategy = \"steps\",\n",
    "    save_strategy = \"epoch\",\n",
    "    save_total_limit=1,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "    # gradient_accumulation_steps=math.ceil(4 / BATCH_SIZE),\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    report_to='wandb',\n",
    "    remove_unused_columns=False,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adamw_8bit\"\n",
    ")"
   ],
   "id": "a15993a3fda30eb3",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:08:13.036166Z",
     "start_time": "2025-04-29T16:08:09.146405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run = wandb.init(\n",
    "    project='dalip-stackoverflow-answer-ranking',\n",
    "    tags=['bi-encoder'],\n",
    "    # if resuming an existing run\n",
    "    id='a5rist4t',\n",
    "    resume='must'\n",
    ")\n",
    "\n",
    "wandb.config.update({\n",
    "    'preprocessing': preprocessor.__dict__,\n",
    "    'model_name': MODEL_NAME,\n",
    "    'vectorizer': {\n",
    "        'vectorization_type': 'embeddings',\n",
    "        'embeddings_pooling': EMBEDDINGS_POOLING,\n",
    "        'max_length': MAX_LENGTH\n",
    "    },\n",
    "    'loss_fn': LOSS\n",
    "})\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=hf_dataset['train'],\n",
    "    eval_dataset=hf_dataset['test'],\n",
    "    compute_loss_func=trainer_loss_fn,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "id": "2809710310e5673f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[32m\u001B[41mERROR\u001B[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mbunnynobugs\u001B[0m to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/stackoverflow-answer-assessment/wandb/run-20250429_160810-a5rist4t</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/bunnynobugs/dalip-stackoverflow-answer-ranking/runs/a5rist4t' target=\"_blank\">clear-capybara-87</a></strong> to <a href='https://wandb.ai/bunnynobugs/dalip-stackoverflow-answer-ranking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/bunnynobugs/dalip-stackoverflow-answer-ranking' target=\"_blank\">https://wandb.ai/bunnynobugs/dalip-stackoverflow-answer-ranking</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/bunnynobugs/dalip-stackoverflow-answer-ranking/runs/a5rist4t' target=\"_blank\">https://wandb.ai/bunnynobugs/dalip-stackoverflow-answer-ranking/runs/a5rist4t</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-29T16:08:13.066662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.train(resume_from_checkpoint=True)\n",
    "run.finish()"
   ],
   "id": "52189f515767bc0b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67365' max='106750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 67365/106750 1:45:22 < 20:52:41, 0.52 it/s, Epoch 3.16/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T17:53:17.429871300Z",
     "start_time": "2025-04-29T14:29:04.564333Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e5fb2679a3a7e25d",
   "outputs": [],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
